\section{Noción de estabilidad}
Sea $A$ un algoritmo de aprendizaje y sea $S (\thicksim D^m) = (Z_1,\dots, Z_m)$. Hablamos de sobreajuste cuando $|L_D(A(S))-L_S(A(S))|$ es grande.
Sea $S^{(i)} = (Z_1,\dots,Z_i,{Z'}, Z_{i+1},\dots,Z_m)$ con ${Z'}$ independiente de los anteriores y  ${Z'} \thicksim D^m$. Lo que esperaríamos de un buen argumento es:
\begin{center}
    $l(A(S^{(i)})),Z_i)*l(A(S)),Z_i) \geq 0$
\end{center}.

\begin{theorem}
Supongamos que $D$ es una distribución. Sea $S (\thicksim D^m) = (Z_1,\dots, Z_m)$, y sea ${Z'} \thicksim D^m$ una observación independiente. Denotamos como $U(m)$ a la distribución uniforme en el conjunto de índices $\{1,\dots,m\}$. Entonces

\begin{center}
$E_S(L_D(A(S)) - L_S(A(S))) = E_{\underset{i\thicksim U(m)}{S \thicksim D^m}}(l(A(S^{(i)})),Z_i) - l(A(S)),Z_i))$
\end{center}

\end{theorem}
\\

\begin{proof}
$E_S(L_D(A(S)) = E_{S,{Z'}}(l(A(S),{Z'})) = E_{\underset{i\thicksim U(m)}{S \thicksim D^m}}(l(A(S^{(i)})),Z_i)$
Por otro lado, $E_S(L_S(A(S)) = E_{S,i}(l(A(S),Z_i)) = E_S(\frac{1}{n} \sum_{i=1}^m l(A(S),Z_i)$
\end{proof}

\begin{definition}
Sea $\varepsilon :\mathbb{N} \rightarrow \mathbb{R}$ monótonamente decreciente. Decimos que el algoritmo $A$ es estable en promedio, bajo reemplazos individuales con tasa $\varepsilon(m)$, si $\forall D$ se tiene que $$E_{\underset{i\thicksim U(m)}{S \thicksim D^m}}(l(A(S^{(i)})),Z_i) - l(A(S)),Z_i)) \leq \varepsilon(m) $$
\end{definition}
